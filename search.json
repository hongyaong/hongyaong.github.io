[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Portfolio",
    "section": "",
    "text": "Welcome to Hong Yao’s project.\nClick on Customer Churn Prediction Analysis or Restaurant Competitor Analysis to look at my school projects in SMU."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About our dataset\n\n\n\n\n\nVariable\nMeaning\nDataType\nNotes\n\n\n\n\nCustomerID\nUnique Identifier that identifies each customer\nint\nNA\n\n\nAge\nAge of the customer in years\nint\nNA\n\n\nGender\nGender of the customer\nchr\nMale or Female\n\n\nTenure\nTotal amount of of months the customer has been with the company\nint\nNA\n\n\nUsage Frequency\nHow often the customer uses the service\nint\nNA\n\n\nSupport Calls\nNumber of customer support calls made by the customer\nint\nNA\n\n\nPayment Delay\nNumber of days a customer's payment is delayed.\nint\nNA\n\n\nSubscription Type\nType of subscription the customer subscribed for\nchr\nStandard, Basic or Premium\n\n\nContract Length\nLength of customer's contract\nchr\nAnnual, Monthly or Quarterly\n\n\nTotal Spend\nTotal amount spent by the customer on the service in USD\nnum\nNA\n\n\nLast Interaction\nThe number of days since the customer's last interaction with the company\nint\nNA\n\n\nChurn\nWhether the customer has churned or not\nint\nChurned = 1, Not Churned = 0"
  },
  {
    "objectID": "eda.html",
    "href": "eda.html",
    "title": "Exploratory Data Analysis",
    "section": "",
    "text": "Attaching package: 'arrow'\n\n\nThe following object is masked from 'package:utils':\n\n    timestamp\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\n\nAttaching package: 'sparklyr'\n\n\nThe following object is masked from 'package:stats':\n\n    filter\n\n\n\n\n# A tibble: 1 × 12\n  CustomerID   Age Gender Tenure `Usage Frequency` `Support Calls`\n       &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;             &lt;dbl&gt;           &lt;dbl&gt;\n1          1     1      0      1                 1               1\n# ℹ 6 more variables: `Payment Delay` &lt;dbl&gt;, `Subscription Type` &lt;dbl&gt;,\n#   `Contract Length` &lt;dbl&gt;, `Total Spend` &lt;dbl&gt;, `Last Interaction` &lt;dbl&gt;,\n#   Churn &lt;dbl&gt;\n\n\n\n\n\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  18.00   29.00   39.00   39.37   48.00   65.00 \n\n\nLooking at the distribution by age, a large portion of our dataset comes from aged 40-50 years old and a low portion comes from age 50-60 years old.\nThe statistic summary of age shows that the mean age is 39.37 and it’s ranging from 18 to 65 years old.\n\n\n\n\n\nFrom the Gender Distribution bar chart, we are able to see that we have more Male than Female in this dataset.\n\n\n\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   1.00   16.00   32.00   31.26   46.00   60.00 \n\n\nLooking at the Distribution by Tenure, it is apparent that the dataset exhibits a generally balanced distribution where majority of Tenure values hover around range of 7000 - 8000 in terms of count. However, for tenure values falling within the ranges of 10-20 and 0-5, there is a slight drop with counts ranging from 6000 to 7000, indicating a comparatively lower frequency of occurrences within these specific tenure ranges.”\nThe statistic summary of tenure shows that the dataset mean tenure is 31.26 and it’s ranging from 1 to 60 Tenure.\n\n\n\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   1.00    9.00   16.00   15.81   23.00   30.00 \n\n\nLooking at the Distribution by Usage Frequency, it is obvious that the dataset exhibits a generally balanced distribution where majority of Tenure values hover around range of 15000 in terms of count. However, for Usage Frequency values &lt; 10, the counts is slightly lower.\nThe statistic summary of Usage Frequency shows that the dataset mean Usage Frequency is 15.81 and it’s ranging from 1 to 30 Usage Frequency.\n\n\n\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  0.000   1.000   3.000   3.604   6.000  10.000 \n\n\nLooking at the Distribution by Support Calls, there is a downward trend in terms of counts as support calls increases. Support calls of 5 onward has a stable frequency of around 20000.\nThe statistic summary of Support Calls shows that the dataset mean Support Calls is 3.604 and it’s ranging from 0 to 10 calls."
  },
  {
    "objectID": "abouttest.html",
    "href": "abouttest.html",
    "title": "abouttest",
    "section": "",
    "text": "Variable\nMeaning\nDataType\nNotes\n\n\n\n\nCustomerID\nUnique Identifier that identifies each customer\nint\nNA\n\n\nAge\nAge of the customer in years\nint\nNA\n\n\nGender\nGender of the customer\nchr\nMale or Female\n\n\nTenure\nTotal amount of of months the customer has been with the company\nint\nNA\n\n\nUsage Frequency\nHow often the customer uses the service\nint\nNA\n\n\nSupport Calls\nNumber of customer support calls made by the customer\nint\nNA\n\n\nPayment Delay\nNumber of days a customer's payment is delayed.\nint\nNA\n\n\nSubscription Type\nType of subscription the customer subscribed for\nchr\nStandard, Basic or Premium\n\n\nContract Length\nLength of customer's contract\nchr\nAnnual, Monthly or Quarterly\n\n\nTotal Spend\nTotal amount spent by the customer on the service in USD\nnum\nNA\n\n\nLast Interaction\nThe number of days since the customer's last interaction with the company\nint\nNA\n\n\nChurn\nWhether the customer has churned or not\nint\nChurned = 1, Not Churned = 0"
  },
  {
    "objectID": "about_dataset.html",
    "href": "about_dataset.html",
    "title": "About Dataset",
    "section": "",
    "text": "Variable\nMeaning\nDataType\nNotes\n\n\n\n\nCustomerID\nUnique Identifier that identifies each customer\nint\nNA\n\n\nAge\nAge of the customer in years\nint\nNA\n\n\nGender\nGender of the customer\nchr\nMale or Female\n\n\nTenure\nTotal amount of of months the customer has been with the company\nint\nNA\n\n\nUsage Frequency\nHow often the customer uses the service\nint\nNA\n\n\nSupport Calls\nNumber of customer support calls made by the customer\nint\nNA\n\n\nPayment Delay\nNumber of days a customer's payment is delayed.\nint\nNA\n\n\nSubscription Type\nType of subscription the customer subscribed for\nchr\nStandard, Basic or Premium\n\n\nContract Length\nLength of customer's contract\nchr\nAnnual, Monthly or Quarterly\n\n\nTotal Spend\nTotal amount spent by the customer on the service in USD\nnum\nNA\n\n\nLast Interaction\nThe number of days since the customer's last interaction with the company\nint\nNA\n\n\nChurn\nWhether the customer has churned or not\nint\nChurned = 1, Not Churned = 0"
  },
  {
    "objectID": "DSA306project.html",
    "href": "DSA306project.html",
    "title": "Customer Churn Prediction Analysis",
    "section": "",
    "text": "Introduction\nFor this project, our group worked on a customer churn dataset. This dataset is centred around a telecommunications company, where it provides information on how customers are utilising the services and also indicates whether a customer has churned. Customer churn denotes whether a customer has decided to discontinue their subscription to the company’s mobile services within a period of time. It allows the company to assess factors contributing to customer turnover and make informed decisions to retain customers. This project aims to propose a model to predict potential customer churners. To do so, spark will be leveraged to push computations and techniques such as exploratory data analysis and modelling will be employed.\nDataset codebook\n\n\n\n\n\nVariable\nMeaning\nDataType\nNotes\n\n\n\n\nCustomerID\nUnique Customer Identifier\nString\nNA\n\n\nAge\nCustomer's Age in Years\nInteger\n18 to 65\n\n\nGender\nCustomer's Gender\nString\nMale or Female\n\n\nTenure\nLength of Customer Subscription in Months\nInteger\n1 to 60\n\n\nUsage Frequency\nCustomer’s Frequency of Daily Service Usage\nInteger\n1 to 30\n\n\nSupport Calls\nNumber of Support Calls made by Customer\nInteger\n0 (None) to 10\n\n\nPayment Delay\nCustomer’s Payment Delay in Days\nInteger\n0 (None) to 30\n\n\nSubscription Type\nChosen Subscription by Customer\nString\nBasic, Standard or Premium\n\n\nContract Length\nCustomer Service Contract Duration\nString\nMonthly, Quarterly or Annually\n\n\nTotal Spend\nCustomer Total Spending on Service in USD\nFloat\nNA\n\n\nLast Interaction\nDays since Customer Last Interact with the Company\nInteger\n1 to 30\n\n\nChurn\nCustomer Discontinuation with the Service\nInteger\n1 (Yes) or 0 (No)\n\n\n\n\n\n\n\nExploratory Data Analysis (EDA)\nTo better understand our dataset, we conducted EDA to examine the distribution of independent variables and their relationships with the dependent variable. To enhance the clarity in our visualizations, we labelled Churn (1 and 0) as “Churn” and “Non-Churn” respectively. The figures accompanying our analysis can be found in the Appendix.\n\n\nFileSystemDataset (query)\nCustomerID: string\nAge: int64\nGender: string\nTenure: int64\nUsage Frequency: int64\nSupport Calls: int64\nPayment Delay: int64\nSubscription Type: string\nContract Length: string\nTotal Spend: float\nLast Interaction: int64\nChurn: int64\n\nSee $.data for the source Arrow object\n\n\n\n\n\n\n\nWe observe a relatively equal distribution of churn and non-churn customers, with 280,492 and 224,714 instances, respectively. This balanced class distribution ensures that the dataset will not introduce bias in model prediction and prevent the model from favouring the majority class.\n\n\n\n\n\nWe can observe that among churn customers, age is uniformly distributed across the 20 to 60 years old range. In contrast, non-churn customers tend to be concentrated between 30 and 50 years old, with a notable decrease in the proportion of aged 50 to 60 years old. Since there is a notable difference in the distribution, Age is possibly a significant variable.\n\n\n\n\n\nWe notice that among churn customers, the number of males and females is quite similar. In contrast, among non-churn customers, there is a considerably higher count of males compared to females. Disparity in distribution suggests that Gender might be significant.\n\n\n\n\n\nThe distribution of tenure does not show a notable disparity between churn and non-churn customers. There are minor variations, with non-churn customers showing slightly higher and lower proportions in the 10 and 20 months range respectively. This suggests that Tenure might be insignificant.\n\n\n\n\n\nThere is a small difference in the distribution of usage frequency within the 0-10 days range, with a slightly higher proportion of churn customers compared to non-churn customers. As such, Usage Frequency might be insignificant.\n\n\n\n\n\nThe majority of non-churn customers make fewer than 4 support calls. As a result, for support call counts less than 4, there are more non-churn customers than churn customers, while the opposite is observed for support call counts between 4 and 10. Notable difference in distribution suggests that Support Calls are significant.\n\n\n\n\n\nWe observe that non-churn customers are concentrated in less than 20 days. However, among churn customers, the distribution is more even, with a slightly higher proportion having payment delays exceeding 20 days. Disparity in distribution seems to suggest that Payment Delay is significant.\n\n\n\n\n\nWe do not observe any distinction in the subscription preferences among churn and non-churn customers respectively. Therefore, Subscription Type might be insignificant.\n\n\n\n\n\nWe noticed that non-churn customers tend to avoid signing up for monthly contracts. Whereas, for churn customers, there is a relatively even distribution. Huge difference in distribution suggests that Contact Length might be significant.\n\n\n\n\n\nWe can observe that churn customers exhibit a relatively even distribution in terms of total amount spent, whereas non-churn customers tend to concentrate on total amount spent exceeding $500 range. Disparity in distribution seems to suggest that Total Spend might be significant.\n\n\n\n\n\nWe observe that churn customers show a relatively even distribution in terms of the number of days since their last interaction with the company. In contrast, a significant proportion of non-churn customers are concentrated around less than 15 days since their last interaction. Notable difference in distribution suggests that Last Interaction is significant.\n\n\n\n\n\n\n\n\nWe observe the absence of significant relationships among the predictors, which indicates a low probability of multicollinearity. Hence, these attributes enhance the model capacity to independently estimate the relationship between independent and target variables. A significant correlation coefficient of 0.52 is observed between Churn and Support Calls. This implies that a higher number of support calls may reflect underlying product issues, leading to increased customer difficulties and a greater likelihood of subscription cancellations, thus, increasing churn rates\nFeature Engineering\nWe have applied various feature engineering techniques to pre-process our features and enhance their quality, before training our models to improve the overall performance.\nWe performed data binning on selected numeric variables, transforming them into categorical variables (Figure 14). Based on our EDA findings, we identify three variables - “Age”, “Total Spend” and “Payment Delay” - that display a non-monotonic relationship (step function) with the target variable. These variables exhibit a uniform distribution within specific intervals, leading us to bin them accordingly based on those intervals.\nWe built a Spark ML pipeline to integrate a series of transformation steps and algorithms on our train dataset into a single workflow. In the initial stage, we utilize the ft_standard_scaler function to standardise our numeric variables on a constant scale. This ensures that our numeric variables maintain a uniform scale and thus, prevents the model from being biassed towards variables with larger scales. Subsequently, we utilise ft_one_hot_encoder functions to encode categorical variables into numerical representations, generating binary columns for each distinct category (except for the base). This allows us to include those variables into our models since most algorithms require numeric inputs. In the final step of our process, following the transformation of our variables, we apply the ml_logistic_regression function on our dataset, given its suitability in binary classification and its ease in interpreting results.\nModel Training and Evaluation\nWe utilise the sdf_random_split function to partition our dataset into training and test subsets, with a 70-30 ratio, and set the seed to 1234 to ensure reproducibility. After constructing our ML pipeline, we employ the ml_fit function to fit the training dataset into the pipeline, generating a pipeline model. We then utilize the ml_transform function to execute the pipeline model on the test dataset which allows us to assess the performance of our model and evaluate its effectiveness in handling unseen data.\nWe decided to utilise three metrics - AreaUnderROC, Precision and Recall - to evaluate the performance of our model using the test dataset. They range from 0 to 1, with a higher value indicating better performance. The AreaUnderROC is useful in evaluating the model’s ability to classify between churn and non-churn customers at various thresholds.\nA confusion matrix was created to calculate the Precision and Recall of our model performance. Precision evaluates the accuracy of positive predictions made by our model, providing us with the proportion of actually churned customers among those predicted as churned. Recall measures our model’s ability to capture all actual churned customers, providing the proportion of correctly predicted churn customers among those who actually churned.\nHaving obtained our models, we can then look to employ regularisation techniques. Regularisation will help prevent overfitting of our model by imposing penalties on our coefficients. There are 3 regularisation techniques considered - LASSO Regularisation, Ridge Regularisation and Elastic Net Regularisation. In order to employ these 3 techniques, we have utilised the ml_cross_validator function to specify our alpha and lambda values. Whereby, elastic_net_param (alpha) has been set from 0 to 1 in increments of 0.2 and reg_param (lambda) has taken the values of 0.001, 0.005 and 0.01. Performance Metric ROC is then used to identify the best set of hyperparameters to be reimplemented into the initial pipeline.\nLogistic Modelling - Model 1\nWe initially begin with a base model, utilising all the available variables in the dataset and maintaining the default threshold within the model function.\n\n\n[1] \"AUC for model 1: 0.935469957012298\"\n\n\n[1] \"Confusion matrix for model 1:\"\n\n\n     [,1]  [,2] \n[1,] 73745 10198\n[2,] 8608  58403\n\n\n  accuracy precision Type 1 error Type 2 error  Recall_1\n1 0.875419 0.8954744    0.1284565    0.1214872 0.8785128\n\n\nLogistic Modelling - Model 1 (CV)\nApplying regularisation, it was determined that the best set of values were 0 and 0.001 for alpha and lambda values respectively. This indicates that a LASSO regularisation was favoured over the other 2 regularisation techniques. Model 1 (CV)’s performance metrics can be viewed in the table below.\n\n\n   areaUnderROC elastic_net_param_1 reg_param_1\n1     0.9353870                 0.8       0.001\n2     0.9353867                 1.0       0.001\n3     0.9353855                 0.6       0.001\n4     0.9353814                 0.4       0.001\n5     0.9353752                 0.2       0.001\n6     0.9353685                 0.0       0.001\n7     0.9352374                 0.0       0.005\n8     0.9352316                 0.2       0.005\n9     0.9352001                 0.4       0.005\n10    0.9351576                 0.6       0.005\n11    0.9350908                 0.8       0.005\n12    0.9350408                 0.0       0.010\n13    0.9349928                 1.0       0.005\n14    0.9349554                 0.2       0.010\n15    0.9348020                 0.4       0.010\n16    0.9345296                 0.6       0.010\n17    0.9341043                 0.8       0.010\n18    0.9334750                 1.0       0.010\n\n\n[1] \"AUC for model 1a: 0.935482660776576\"\n\n\n[1] \"Confusion matrix for model 1a:\"\n\n\n     [,1]  [,2] \n[1,] 73690 10253\n[2,] 8536  58475\n\n\n   accuracy precision Type 1 error Type 2 error    Recall\n1 0.8755316 0.8961886    0.1273821    0.1221424 0.8778576\n\n\nIt is observed that there are slight improvements to the Model 1 (CV)’s performance relative to Model 1. In which, we observe that the ROC and Precision values increase in its 4th and 3rd significant figure respectively. Whereas, a decrease in Recall in its 3rd significant figure is observed.\nLogistic Modelling - Model 2\nWe then look to create an alternative model that seeks to drop variables that seem to have less explanatory power in determining churned and non-churned customers. This is done primarily through EDA. It is subsequently determined that variables - Tenure, Subscription Type and Usage Frequency be dropped.\n\n\n[1] \"AUC for model 2: 0.935282038899156\"\n\n\n[1] \"Confusion matrix for model 2:\"\n\n\n     [,1]  [,2] \n[1,] 73731 10212\n[2,] 8610  58401\n\n\n  accuracy precision Type 1 error Type 2 error   Recall\n1 0.875313 0.8954348    0.1284864     0.121654 0.878346\n\n\nLogistic Modelling - Model 2 (CV)\nAfter regularisation, it was determined that the best set of values were 0 and 0.001 for alpha and lambda values respectively. This indicates that a LASSO regularisation was favoured over the other 2 regularisation techniques. Model 2 (CV)’s performance metrics can be viewed in the table below.\n\n\n   areaUnderROC reg_param_1 elastic_net_param_1\n1     0.9351262       0.001                 1.0\n2     0.9351211       0.001                 0.8\n3     0.9351179       0.001                 0.6\n4     0.9351154       0.001                 0.4\n5     0.9351088       0.001                 0.2\n6     0.9351037       0.001                 0.0\n7     0.9349734       0.005                 0.0\n8     0.9349694       0.005                 0.2\n9     0.9349468       0.005                 0.4\n10    0.9349047       0.005                 0.6\n11    0.9348408       0.005                 0.8\n12    0.9347757       0.010                 0.0\n13    0.9347503       0.005                 1.0\n14    0.9347043       0.010                 0.2\n15    0.9345486       0.010                 0.4\n16    0.9342901       0.010                 0.6\n17    0.9338955       0.010                 0.8\n18    0.9333120       0.010                 1.0\n\n\n[1] \"AUC for model 2a: 0.935280551815638\"\n\n\n[1] \"Confusion matrix for model 2a:\"\n\n\n     [,1]  [,2] \n[1,] 73696 10247\n[2,] 8568  58443\n\n\n   accuracy precision Type 1 error Type 2 error    Recall\n1 0.8753594 0.8958475    0.1278596    0.1220709 0.8779291\n\n\nComparing the differences in performance metrics between Model 3 and Model 3 (CV), there are little differences in their values. The same ROC values are obtained, Precision and Recall values increased and decreased in its 4th significant figure respectively.\nConclusion\nObserving across the performance metrics of the proposed models, there are little changes in values. In particular, changes including improvements to the values all occur within the 3rd or 4th significant figure which arguably does not represent major improvements across the models. Hence, this suggests that the models proposed have similar predictive capabilities. Keeping this in mind, we can pivot our focus to the principle of parsimony which favours simpler models over complex models without compromising on predictive power. Hence, the principle of parsimony dictates that Model 2 is more favourable due to having fewer variables. Furthermore, to prevent overfitting, regularisation techniques are applied, thus, we can conclude that Model 2 (CV) is an overall better model.\nCredits\nChao Soon En Joy\nChen Xiangzhen Samson\nRachel Tan Yan Ning\nWee Su Ying"
  },
  {
    "objectID": "MKTG228project.html",
    "href": "MKTG228project.html",
    "title": "Restaurant Competitor Analysis",
    "section": "",
    "text": "Introduction\nThis is a restaurant competitor analysis project featuring OBON Sushi Bar Ramen and Raijin.\nOBON Sushi Bar Ramen (OBON) can be viewed as a direct competitor to Raijin Ramen (Rajin), primarily because of their shared specialisation in Ramen dishes, comparable pricing, and close proximity, as both restaurants are located within a 5-kilometre or 8-minute drive radius of each other. Furthermore, OBON aligns with Rajin in terms of its designated rest day, parking facilities, and wheelchair accessibility, eliminating additional variables for consideration in our analysis.\nHowever, a notable distinction between the two establishments is their ambience. While Rajin offers a more traditional restaurant experience, characterised by its attributes and standard opening hours, OBON caters to a distinct customer segment. OBON sets itself apart through its extended opening hours, incorporation of music, and the inclusion of categories like Cocktail Bars and Nightlife, signalling its appeal to a different demographic seeking a vibrant and late-night dining experience.\nData preparation\nWe counted NA checks to see if there is any missing values, and found that for the dataset given, there was no missing values.\n\n\n\n\n\nStar Rating Distribution\nThis chart indicates that Rajin boasts an overall superior rating, evident from its higher percentage of 5-star reviews compared to OBON’s more evenly distributed dataset. This observation is reinforced by the reviews dataset, which reveals an average star score of 4.21 for Rajin and 3.95 for OBON. Based on this star rating distribution, one could reasonably infer that Rajin offers a superior dining experience. Nonetheless, it’s imperative to consider the disparity in review counts, with OBON accumulating 707 reviews and Rajin 594. This discrepancy implies that OBON may have served a more diverse customer demographic, potentially increasing the likelihood of receiving unfavourable reviews. Thus, a more comprehensive analysis is warranted to make a definitive determination regarding the superiority of these two restaurants.\n\n\n\n\n\nAverage Star Rating Over Time\nA 30-day analysis window was selected as it strikes a balance between granularity and capturing overall trends. A 14-day frame might fail to capture broader patterns, while a 90-day frame could smooth nuances in the data frame. Hence, a 30-day window allows for a more insightful analysis of weekly movements and long-term trends.\nAnalysis:\nIn the initial years of their establishment, both Rajin (2018) and OBON (2015) encountered a decline in their ratings. This trend is often anticipated for new restaurants, given that time is required to gain public trust and grow in popularity to become an established brand. However, OBON’s initial dip in ratings persisted for a longer duration compared to Rajin. This prolonged decline suggests the possibility of a shifting local preference and growing acceptance of Japanese cuisine, which may have impacted OBON’s performance.\nFurthermore, during the period from 2019 to mid-2021, both restaurants experienced significant fluctuations in their performance. Notably, when one restaurant’s ratings declined, the other tended to rise. This observation suggests a competitive dynamic between the two establishments, marked by their exploration of diverse promotional and marketing strategies to grow their market share.\nLastly, the decline in late 2021 in reviews from both restaurants could indicate an industry or location-specific disruption. For example, there could have been a shortage of a common ingredient or seafood that is popular in ramen, served by these two restaurants. Alternatively, a new restaurant could have opened in the vicinity of Rajin and OBON, its novelty might have temporarily redirected customers to their establishment instead.\nFrom early 2018 to early 2020, Rajin might have had some competitor advantage that allowed them to run effective marketing promotions and campaigns or employ a superior kitchen staff that allowed them to garner high-rated reviews. OBON might likely have only started to dedicate more effort to enhancing its ambience and food quality to better appeal to its targeted customer base, after attaining one of its lowest performances in reviews since its opening in mid-2019. Consequently, achieving an upward trajectory of high-rated reviews steadily rising against Raijin.\nFrom late 2020 to 2021, it is likely that both businesses were affected by the COVID-19 pandemic which might have deterred customers from dining out in restaurants. Raijin likely adapted much quicker by adopting a food delivery model, with marketing promotions to maintain, or even boost sales.\nOn the other hand, OBON targets a broader spectrum of consumers, based on it fulfilling a broader range of categories. This might have made it more difficult for them to curate effective marketing campaigns that can effectively target all its customers, resulting in initial disadvantages compared to Rajin. OBON likely took longer to find a suitable marketing and business strategy to effectively compete with Rajin, and thus caught up later, as shown by the converging lines between the average ratings of Raijin and OBON closer to the third quarter of 2021.\n\n\n\n\n\nText Analysis\nUsing R’s Afinn and Bing dictionary, we did text analysis. Both restaurants exhibit an overall positive sentiment, with the competitor outperforming the focal restaurant in both lexicons (afinn and bing). However, the competitor achieved a higher score in the afinn analysis compared to the bing analysis. This difference may stem from the measurement tool itself, as afinn has a wider sentiment score range (-5 to 5) compared to bing’s narrower range (-1 to 1). The broader range of afinn likely assigned larger positive values (2 to 5) to words in the reviews of the competitor restaurant, contributing to its better score.\n\n\n\n\n\n\n\n\nA total of 20-30 words as the bag of words for food quality (FQ) was generated to increase the robustness of our result. For Raijin, we have 59% of words being relevant, and the remaining as irrelevant to food quality. The same bag of words was used to analyse the competitor. For OBON, almost half (50.2%) of the words are relevant, and the rest are irrelevant to food quality.\n\n\n\n\n\n\n\n\nSentiment Analysis\nAfinn was chosen for sentiment analysis to accentuate the differences in sentiments between Raijin and OBON. Reviews discussing food quality consistently display high positive sentiments in both restaurants. OBON stands out with higher positive sentiments in both ‘relevant to FQ’ and ‘not relevant to FQ’ categories. This suggests two key findings: OBON’s reviews contain more positive food quality factors than Raijin’s, and non-food factors like ambience, accessibility, and service quality contribute to OBON’s positive sentiment.\nFor managerial implications, both restaurants can leverage positive food quality sentiments in their marketing strategies to attract and retain customers. For Raijin, which performed less favourably, there’s an opportunity to conduct an internal analysis focusing on enhancing not only food quality but also non-food aspects like extending opening hours from 9 to 10 pm instead of its original 8pm. Other non-food aspects such as ambience, music, and service quality can elevate the overall dining experience and cultivate more positive reviews. To further enhance the analysis of customer feedback, a more detailed approach could be implemented. This involves creating distinct bags of words for various categories, including ambience, service, delivery, and cleanliness. This comprehensive strategy can lead to improvements in both the quality and quantity of reviews, ultimately enhancing the restaurant’s reputation.\nWe can enhance our sentiment analysis by creating word clouds of positive and negative words. This approach helps us identify the most frequently mentioned words by customers, thus enabling further improvements in our analysis.\nCredits\nCherilyn Nicole Chan Tze Ling\nGoh Hai Liang\nJoyanna Jiang\nRyan Lim Jian Song"
  }
]